import yfinance as yf
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense, Dropout, LSTM
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from datetime import timedelta
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import IsolationForest
import random
import tensorflow as tf
from scipy.stats import ttest_rel
from scipy.stats import zscore
from prophet import Prophet
from curl_cffi import requests
from pyESN import ESN
from scipy import stats
import json
import matplotlib.pyplot as plt
import platform
import os

# yfinance 429 ìš°íšŒ ì„¸ì…˜ ì ìš©
session = requests.Session(impersonate="chrome")

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows ê¸°ì¤€)
if platform.system() == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'

# ì €ì¥ëœ í´ë“œ ê²°ê³¼ íŒŒì¼ ì´ë¦„
TSS_RESULT_FILE = "gru_lstm_tss_results1.npz"

# best_gru_config.json íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
try:
    with open("best_gru_config.json", "r") as f:
        best_gru_config = json.load(f)
    with open("best_lstm_config.json", "r") as f:
        best_lstm_config = json.load(f)
except FileNotFoundError:
    print("GA íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    best_gru_config = {'gru_units1': 128, 'gru_units2': 64, 'dropout': 0.2, 'batch_size': 32}
    best_lstm_config = {'lstm_units1': 128, 'lstm_units2': 64, 'dropout': 0.2, 'batch_size': 32}

# 1. ë°ì´í„° ë¡œë”© ë° ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
df = yf.download("GOOGL", period="3000d", auto_adjust=True, session=session)

print(df)
# df.columnsê°€ MultiIndexì¸ ê²½ìš° ì²˜ë¦¬
if isinstance(df.columns, pd.MultiIndex):
    df.columns = df.columns.get_level_values(0)
# 'Close' ì»¬ëŸ¼ì´ Seriesê°€ ì•„ë‹ˆë¼ DataFrameìœ¼ë¡œ ë¡œë“œë˜ëŠ” ê²½ìš°ë¥¼ ë°©ì§€
if isinstance(df['Close'], pd.DataFrame):
    df['Close'] = df['Close'].squeeze()

# ì´ë™í‰ê· 
df['MA7'] = df['Close'].rolling(window=7).mean()
df['MA14'] = df['Close'].rolling(window=14).mean()
df['MA50'] = df['Close'].rolling(window=50).mean()


# RSI (Relative Strength Index)
def calculate_rsi(data, period=14):
    delta = data.diff(1)
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss.replace(0, np.nan)
    rsi = 100 - (100 / (1 + rs))
    return rsi


df['RSI'] = calculate_rsi(df['Close'])


# MACD (Moving Average Convergence Divergence)
def calculate_macd(data, short_period=12, long_period=26, signal_period=9):
    short_ema = data.ewm(span=short_period, adjust=False).mean()
    long_ema = data.ewm(span=long_period, adjust=False).mean()
    macd_line = short_ema - long_ema
    signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()
    macd_histogram = macd_line - signal_line
    return macd_line, signal_line, macd_histogram


df['MACD_Line'], df['MACD_Signal'], df['MACD_Hist'] = calculate_macd(df['Close'])

# NaN ê°’ ì²˜ë¦¬ (ì´ìƒì¹˜ ì œê±° ì „ì— ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ ì•ˆì „)
df.ffill(inplace=True)
df.bfill(inplace=True)
df.dropna(inplace=True)

# ì´ìƒì¹˜ ì œê±° (ì¶”ê°€ëœ ë¶€ë¶„)
Z_THRESHOLD = 3
GAP_THRESHOLD = 0.1
MA_WINDOW = 5
VOLUME_MEAN_THRESHOLD = 10000

if not df.empty:
    df["log_return"] = np.log(df["Close"] / df["Close"].shift(1))
    if not df["log_return"].dropna().empty:
        z_scores = zscore(df["log_return"].dropna())
        z_score_series = pd.Series(z_scores, index=df["log_return"].dropna().index)
        df["z_log_return"] = z_score_series.reindex(df.index)
    else:
        df["z_log_return"] = np.nan
    df["ma_5"] = df["Close"].rolling(window=MA_WINDOW).mean()
    df["gap_ratio"] = (df["Close"] - df["ma_5"]) / df["ma_5"]
    df["true_event"] = (df["z_log_return"].abs() > Z_THRESHOLD) & (df["gap_ratio"].abs() > GAP_THRESHOLD)
    df["maybe_bad_data"] = (
            (df["Volume"] < 1) |
            (df["Close"] < 1) |
            ((df["Close"] == df["Open"]) & (df["Close"] == df["High"]) & (df["Close"] == df["Low"])) |
            (df["High"] < df["Low"]) |
            ((df["Close"].pct_change().abs() > 0.7) & (df["Volume"].rolling(3).mean() < 10000))
    )
    df["likely_real_event"] = (
            (df["Volume"].rolling(3).mean() > df["Volume"].rolling(30).mean() * 1.5) |
            ((df["z_log_return"].abs() > Z_THRESHOLD) & (df["gap_ratio"].abs() > GAP_THRESHOLD) & (
                    df["Volume"] > VOLUME_MEAN_THRESHOLD))
    )
    df["clean_target"] = df["true_event"] & df["maybe_bad_data"] & ~df["likely_real_event"]
    df["Close_clean"] = df["Close"]
    df.loc[df["clean_target"], "Close_clean"] = np.nan
    df["Close_clean"] = df["Close_clean"].fillna(
        df["Close_clean"].rolling(window=MA_WINDOW, min_periods=1, center=True).mean()
    )
    df["Anomaly"] = df["clean_target"].astype(int)
    df["Close"] = df["Close_clean"]
    df.drop(columns=["Close_clean"], inplace=True)
else:
    print("ê²½ê³ : ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆì–´ ì´ìƒì¹˜ ì œê±°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

# ê²°ì¸¡ ì œê±° (ì´ìƒì¹˜ ì œê±° í›„ ë°œìƒí•  ìˆ˜ ìˆëŠ” NaN ìµœì¢… ì œê±°)
df.ffill(inplace=True)
df.bfill(inplace=True)
df.dropna(inplace=True)

# 2. GC/DC ë¶„ì„
df['GC'] = np.where((df['MA7'] > df['MA50']) & (df['MA7'].shift(1) <= df['MA50'].shift(1)), 1, 0)
df['DC'] = np.where((df['MA7'] < df['MA50']) & (df['MA7'].shift(1) >= df['MA50'].shift(1)), -1, 0)
df['GC/DC Signal'] = df['GC'] + df['DC']


# 3. ì‹œê³„ì—´ ë°ì´í„° ìƒì„± í•¨ìˆ˜(ë‹¤ì¤‘ Dense ì¶œë ¥)
def create_sequences(data, target_idx, seq_len, future_len):
    x, y = [], []
    if len(data) <= seq_len + future_len:
        print(f"ê²½ê³ : ë°ì´í„° ê¸¸ì´ê°€ ì‹œí€€ìŠ¤ ìƒì„±ì— ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìµœì†Œ {seq_len + future_len} í•„ìš”, í˜„ì¬ {len(data)}.")
        return np.array([]), np.array([])
    for i in range(seq_len, len(data) - future_len):
        x.append(data[i - seq_len:i])
        y.append(data[i:i + future_len, target_idx])
    return np.array(x), np.array(y)


# ESNìš© ì‹œê³„ì—´ ìƒì„± í•¨ìˆ˜ (ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
def create_ESN_sequences(data, seq_length):
    x, y = [], []
    for i in range(len(data) - seq_length):
        x.append(data[i:i + seq_length])
        y.append(data[i + seq_length])  # ESNì€ ê¸°ë³¸ì ìœ¼ë¡œ ë‹¨ì¼ ìŠ¤í… ì˜ˆì¸¡ì„ ëª©í‘œë¡œ í•˜ë¯€ë¡œ yëŠ” ë‹¨ì¼ ê°’
    return np.array(x), np.array(y)


# 4. ì •ê·œí™” ('Anomaly' ì»¬ëŸ¼ í¬í•¨)
features = ['Close', 'MA7', 'MA14', 'MA50', 'RSI', 'MACD_Line', 'MACD_Signal', 'MACD_Hist', 'Anomaly']
num_features = len(features)
full_scaler = MinMaxScaler()
scaled_full = full_scaler.fit_transform(df[features])
close_scaler = MinMaxScaler()
scaled_close = close_scaler.fit_transform(df[['Close']])


# 5. ëª¨ë¸ ì •ì˜
def create_gru_model(seq_len, num_features, units1, units2, dropout_rate, future_days):
    model = Sequential([
        GRU(units1, return_sequences=True, input_shape=(seq_len, num_features)),
        Dropout(dropout_rate),
        GRU(units2),
        Dropout(dropout_rate),
        Dense(future_days)
    ])
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model


def create_lstm_model(seq_len, num_features, units1, units2, dropout_rate, future_days):
    model = Sequential([
        LSTM(units1, return_sequences=True, input_shape=(seq_len, num_features)),
        Dropout(dropout_rate),
        LSTM(units2),
        Dropout(dropout_rate),
        Dense(future_days)
    ])
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model


# âœ… ESN ì‹¤í–‰ í•¨ìˆ˜ (ë‹¨ê¸° ì˜ˆì¸¡ ê¸°ì¤€) - íŒŒë¼ë¯¸í„° ì´ë¦„ì„ ê¸°ì¡´ main ì½”ë“œì— ë§ê²Œ ì¡°ì •
def run_esn(scaled_data_full, scaled_data_close, seq_len, split_ratio, scaler_close_obj):
    # ESN ì…ë ¥ ì‹œí€€ìŠ¤ ìƒì„±: X_esnì€ ë‹¤ë³€ëŸ‰(ì „ì²´ íŠ¹ì„±), y_esnì€ ë‹¨ë³€ëŸ‰(ì¢…ê°€)
    # y_esnì˜ targetì€ scaled_data_closeì—ì„œ ê°€ì ¸ì˜´
    X_esn_raw, _ = create_ESN_sequences(scaled_data_full, seq_len)
    _, y_esn_raw = create_ESN_sequences(scaled_data_close, seq_len)  # ESNì˜ yëŠ” ë‹¤ìŒ ë‚  1ê°œë§Œ ì˜ˆì¸¡

    # ESN ì…ë ¥ì— ë§ê²Œ X_esn_rawë¥¼ 2Dë¡œ reshape (samples, seq_len * num_features)
    # scaled_data_full.shape[1]ì€ ì›ë˜ num_features
    X_esn = X_esn_raw.reshape(X_esn_raw.shape[0], seq_len * scaled_data_full.shape[1])
    # y_esn_rawëŠ” (samples, 1) í˜•íƒœì´ë¯€ë¡œ 1Dë¡œ flatten
    y_esn = y_esn_raw.flatten()  # (samples,) í˜•íƒœë¡œ ë§Œë“¦

    # train/validation split
    split_index = int(len(X_esn) * split_ratio)
    X_esn_train, X_esn_val = X_esn[:split_index], X_esn[split_index:]
    y_esn_train, y_esn_val = y_esn[:split_index], y_esn[split_index:]

    # ESN ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ
    # n_inputsëŠ” X_esn.shape[1] (seq_len * num_features)
    # n_outputsëŠ” 1 (ì¢…ê°€ ë‹¨ì¼ ì˜ˆì¸¡)
    esn = ESN(
        n_inputs=X_esn.shape[1],
        n_outputs=1,
        n_reservoir=200,
        spectral_radius=0.95,
        sparsity=0.2,
        noise=0.001,
        random_state=42
    )
    esn.fit(X_esn_train, y_esn_train)

    # ì˜ˆì¸¡ ìˆ˜í–‰
    pred_val_esn_scaled = esn.predict(X_esn_val)
    # ì˜ˆì¸¡ê°’ì„ [0, 1] ë²”ìœ„ë¡œ í´ë¦¬í•‘ (ì •ê·œí™”ëœ ê°’ì´ë¯€ë¡œ)
    pred_val_esn_scaled = np.clip(pred_val_esn_scaled, 0, 1)

    # ì˜ˆì¸¡ê°’ ì—­ì •ê·œí™”
    # pred_val_esn_scaledëŠ” (n_samples,) í˜•íƒœì´ë¯€ë¡œ reshape(-1, 1)
    pred_val_esn_close = scaler_close_obj.inverse_transform(pred_val_esn_scaled.reshape(-1, 1))

    # ESNì€ ë‹¨ì¼ ìŠ¤í… ì˜ˆì¸¡ì´ë¯€ë¡œ, y_esn_valì— í•´ë‹¹í•˜ëŠ” ì‹¤ì œê°’ì„ ì—­ì •ê·œí™”í•˜ì—¬ ë°˜í™˜
    real_val_esn_close = scaler_close_obj.inverse_transform(y_esn_val.reshape(-1, 1))

    return pred_val_esn_close, real_val_esn_close, X_esn_val  # X_esn_valë„ ë°˜í™˜í•˜ì—¬ ë‚˜ì¤‘ì— ì „ì²´ ì˜ˆì¸¡ì— ì‚¬ìš©


# 6. ë°ì´í„° ë¶„í•  (Time Series Split ì ìš©)
seq_len, future_days = 60, 5
target_idx = features.index('Close')

if df.empty:
    print("ê²½ê³ : ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ì–´ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    gru_predicted_series_avg = pd.Series()
    lstm_predicted_series_avg = pd.Series()
    prophet_predicted_series = pd.Series()
    pred_val_esn_close_for_plot = pd.Series()  # ESN ì¶”ê°€
    gru_true_prices_for_plot = pd.Series()
    gru_predicted_prices_for_plot = pd.Series()
    lstm_predicted_prices_for_plot = pd.Series()
else:
    X, y = create_sequences(scaled_full, target_idx, seq_len, future_days)

    # ESNì„ ìœ„í•œ ì¶”ê°€ ë³€ìˆ˜
    # ESNì€ TimeSeriesSplit ë‚´ë¶€ì—ì„œ ëŒë¦¬ëŠ” ëŒ€ì‹ , ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ í•œë²ˆ í•™ìŠµ/ì˜ˆì¸¡ í›„,
    # ê²€ì¦ì…‹ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì„ ì˜ë¼ì„œ ë¹„êµí•©ë‹ˆë‹¤.
    # ê¸°ì¡´ run_esn_and_plot í•¨ìˆ˜ê°€ splitì„ ë‚´ë¶€ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ë¯€ë¡œ,
    # ì—¬ê¸°ì„œëŠ” ì „ì²´ scaled_fullì„ ì „ë‹¬í•˜ê³  ë‚´ë¶€ì—ì„œ split_ratioë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # split_ratioëŠ” TimeSeriesSplitì˜ ë§ˆì§€ë§‰ í´ë“œ ë¹„ìœ¨ì— ë§ì¶° ì¡°ì •í•©ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ì „ì²´ ë°ì´í„°ì…‹ì˜ í›ˆë ¨/ê²€ì¦ ë¶„í• ì„ í•œë²ˆë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    # ESNì˜ í•™ìŠµ/ê²€ì¦ ë¹„ìœ¨ ì„¤ì • (ì˜ˆ: í›ˆë ¨ 80%, ê²€ì¦ 20%)
    # GRU/LSTMì˜ ë§ˆì§€ë§‰ í´ë“œì˜ test_idx ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ESNì˜ split_ratioë¥¼ ê²°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì „ì²´ ë°ì´í„°ì˜ 80%ë¥¼ í›ˆë ¨, 20%ë¥¼ ê²€ì¦ìœ¼ë¡œ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤.
    esn_split_ratio = 0.8
    pred_val_esn_close, real_val_esn_close, X_esn_val_original_shape = run_esn(
        scaled_full, scaled_close, seq_len, esn_split_ratio, close_scaler
    )
    if X.size == 0 or y.size == 0:
        print("ê²½ê³ : ìƒì„±ëœ ì‹œí€€ìŠ¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        gru_predicted_series_avg = pd.Series()
        lstm_predicted_series_avg = pd.Series()
        prophet_predicted_series = pd.Series()
        pred_val_esn_close_for_plot = pd.Series()  # ESN ì¶”ê°€
        gru_true_prices_for_plot = pd.Series()
        gru_predicted_prices_for_plot = pd.Series()
        lstm_predicted_prices_for_plot = pd.Series()
    else:
        if os.path.exists(TSS_RESULT_FILE):
            print(f"[âœ”] ê¸°ì¡´ TimeSeriesSplit ê²°ê³¼ íŒŒì¼ì´ ì¡´ì¬í•¨ â†’ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: {TSS_RESULT_FILE}")
            data = np.load(TSS_RESULT_FILE)
            gru_preds_all = data['gru_preds_all']
            gru_trues_all = data['gru_trues_all']
            lstm_preds_all = data['lstm_preds_all']
            lstm_trues_all = data['lstm_trues_all']
        else:
            print(f"[â—] ê²°ê³¼ íŒŒì¼ì´ ì—†ìŒ â†’ GRU/LSTM TimeSeriesSplit í•™ìŠµ ìˆ˜í–‰ ì¤‘...")
            n_splits = 5
            tscv = TimeSeriesSplit(n_splits=n_splits)

            print("\n--- GRU & LSTM ëª¨ë¸ TSS ê¸°ë°˜ í•™ìŠµ ì‹œì‘ ---")
            gru_preds_all = []
            gru_trues_all = []
            lstm_preds_all = []
            lstm_trues_all = []

            for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
                print(f"\n--- Fold {fold + 1} ---")
                X_train, X_test = X[train_idx], X[test_idx]
                y_train, y_test = y[train_idx], y[test_idx]

                # === GRU í•™ìŠµ ===
                gru_model = create_gru_model(seq_len, num_features,
                                             best_gru_config['gru_units1'],
                                             best_gru_config['gru_units2'],
                                             best_gru_config['dropout'],
                                             future_days)
                gru_callbacks = [EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
                                 ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)]
                gru_model.fit(X_train, y_train, epochs=50, batch_size=best_gru_config['batch_size'],
                              validation_data=(X_test, y_test), callbacks=gru_callbacks, verbose=1)
                gru_pred = gru_model.predict(X_test)
                gru_preds_all.extend(gru_pred)
                gru_trues_all.extend(y_test)

                # === LSTM í•™ìŠµ ===
                #lstm_model = create_lstm_model(seq_len, num_features, 128, 64, 0.2, future_days)
                lstm_model = create_lstm_model(seq_len, num_features,
                                               best_lstm_config['lstm_units1'],
                                               best_lstm_config['lstm_units2'],
                                               best_lstm_config['dropout'],
                                               future_days)
                lstm_callbacks = [EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
                    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)]
                lstm_model.fit(X_train, y_train, epochs=50, batch_size=32,
                               validation_data=(X_test, y_test), callbacks=lstm_callbacks, verbose=1)
                lstm_pred = lstm_model.predict(X_test)
                lstm_preds_all.extend(lstm_pred)
                lstm_trues_all.extend(y_test)

                # í•™ìŠµ ê²°ê³¼ ì €ì¥
            np.savez(TSS_RESULT_FILE,
                    gru_preds_all=np.array(gru_preds_all),
                    gru_trues_all=np.array(gru_trues_all),
                    lstm_preds_all=np.array(lstm_preds_all),
                    lstm_trues_all=np.array(lstm_trues_all))
            print(f"[ğŸ’¾] K-Fold ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ {TSS_RESULT_FILE}")

        # --- ê²°ê³¼ ì •ë¦¬ ë° ì—­ì •ê·œí™” (TSS ëª¨ë“  í´ë“œì˜ ì˜ˆì¸¡ê°’ ì·¨í•©) ---
        gru_predicted_common_tss = close_scaler.inverse_transform(np.array(gru_preds_all))
        actual_common_gru_tss = close_scaler.inverse_transform(np.array(gru_trues_all))

        lstm_predicted_common_tss = close_scaler.inverse_transform(np.array(lstm_preds_all))
        actual_common_lstm_tss = close_scaler.inverse_transform(np.array(lstm_trues_all))

        # --- Prophet ëª¨ë¸ ì¶”ê°€ ---
        print("\n--- Prophet ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")
        prophet_df = df.reset_index()[['Date', 'Close', 'RSI', 'GC/DC Signal']].copy()
        prophet_df.columns = ['ds', 'y', 'rsi', 'signal']
        prophet_df['rsi'] = prophet_df['rsi'].astype(np.float64)
        prophet_df['signal'] = prophet_df['signal'].astype(np.float64)
        prophet_df['y'] = prophet_df['y'].astype(np.float64)
        prophet_df.dropna(subset=['ds', 'y', 'rsi', 'signal'], inplace=True)

        m = Prophet(daily_seasonality=True, yearly_seasonality=True, weekly_seasonality=True)
        m.add_regressor('rsi')
        m.add_regressor('signal')
        m.fit(prophet_df)

        future_prophet_df = pd.DataFrame({'ds': df.index})
        future_prophet_df = pd.merge(future_prophet_df, prophet_df[['ds', 'rsi', 'signal']], on='ds', how='left')
        future_prophet_df['rsi'].fillna(method='ffill', inplace=True)
        future_prophet_df['signal'].fillna(method='ffill', inplace=True)
        future_prophet_df['rsi'].fillna(method='bfill', inplace=True)
        future_prophet_df['signal'].fillna(method='bfill', inplace=True)

        prophet_forecast = m.predict(future_prophet_df)
        prophet_predicted_series = prophet_forecast.set_index('ds')['yhat']

        # --- GRU, LSTM ìµœì¢… ëª¨ë¸ ì¬í•™ìŠµ (ì „ì²´ ë°ì´í„° ì‚¬ìš©) ---
        print("\n--- GRU ìµœì¢… ëª¨ë¸ (ì „ì²´ ë°ì´í„°) í•™ìŠµ ì‹œì‘ ---")
        gru_model_final = create_gru_model(seq_len, num_features,
                                           best_gru_config['gru_units1'],
                                           best_gru_config['gru_units2'],
                                           best_gru_config['dropout'],
                                           future_days)

        gru_model_final.fit(X, y, epochs=50, batch_size=best_gru_config['batch_size'], validation_split=0.1, shuffle=False, verbose=1)


        print("\n--- LSTM ìµœì¢… ëª¨ë¸ (ì „ì²´ ë°ì´í„°) í•™ìŠµ ì‹œì‘ ---")
        lstm_model_final = create_lstm_model(seq_len, num_features, best_lstm_config['lstm_units1'],
                                             best_lstm_config['lstm_units2'], best_lstm_config['dropout'], future_days)

        lstm_model_final.fit(X, y, epochs=50, batch_size= best_lstm_config['batch_size'], validation_split=0.1, shuffle=False, verbose=1)

        # 9. ìµœê·¼ 100ì¼ ì˜ˆì¸¡ ë¹„êµ (GRU, LSTM, Prophet, ESN)
        latest_date = df.index[-1]
        start_date_plot = latest_date - timedelta(days=100)

        actual_daily_plot = df['Close'].loc[start_date_plot:].copy()

        gru_pred_for_plot = gru_model_final.predict(X)
        lstm_pred_for_plot = lstm_model_final.predict(X)
        dates_for_predictions = df.index[seq_len: seq_len + len(X)]

        gru_predicted_series_for_plot = pd.Series(close_scaler.inverse_transform(gru_pred_for_plot)[:, 0],
                                                  index=dates_for_predictions)
        lstm_predicted_series_for_plot = pd.Series(close_scaler.inverse_transform(lstm_pred_for_plot)[:, 0],
                                                   index=dates_for_predictions)

        # ESNì˜ ì˜ˆì¸¡ ê²°ê³¼ ì¤€ë¹„: run_esn í•¨ìˆ˜ì—ì„œ ë°˜í™˜ëœ validation set ì˜ˆì¸¡ê°’
        # ESN ì˜ˆì¸¡ê°’ì€ ì´ë¯¸ ì—­ì •ê·œí™”ë˜ì–´ ìˆê³ , ì‹¤ì œê°’ë„ ì—­ì •ê·œí™”ë˜ì–´ ìˆìŒ
        # ESN ì˜ˆì¸¡ì€ ë‹¨ì¼ ìŠ¤í…ì´ë¯€ë¡œ, í•´ë‹¹ ì˜ˆì¸¡ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ë§ì¶”ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
        # run_esnì—ì„œ ë°˜í™˜ëœ X_esn_val_original_shapeëŠ” (samples, seq_len * num_features) í˜•íƒœ
        # ì´ ë°ì´í„°ì˜ ì›ë˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ì„œ ESN ì˜ˆì¸¡ê°’ Seriesë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.

        # df ì¸ë±ìŠ¤ì™€ X_esn_val_original_shape (scaled_full ê¸°ë°˜) ì¸ë±ìŠ¤ ë§¤í•‘
        # ESNì˜ ê²€ì¦ì…‹ ì‹œì‘ ì¸ë±ìŠ¤
        esn_val_start_idx_in_original_df = int(len(scaled_full) * esn_split_ratio)
        esn_val_end_idx_in_original_df = len(scaled_full) - 1  # ESNì˜ y_esnì€ ë§ˆì§€ë§‰ ê°’ê¹Œì§€ ì˜ˆì¸¡

        # ESN ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜ëŠ” len(data) - seq_length ê¹Œì§€ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        # X_esnì€ (len(data) - seq_length) ê°œì˜ ì‹œí€€ìŠ¤ë¥¼ ê°€ì§‘ë‹ˆë‹¤.
        # y_esnì€ X_esnì˜ ê° ì‹œí€€ìŠ¤ ë‹¤ìŒ ë‚ ì˜ ê°’ì…ë‹ˆë‹¤.
        # ë”°ë¼ì„œ ESN ì˜ˆì¸¡ê°’ì˜ ë‚ ì§œëŠ” df.index[seq_len + split_index : seq_len + len(X_esn)] ì…ë‹ˆë‹¤.

        # ESN ì˜ˆì¸¡ê°’ì— í•´ë‹¹í•˜ëŠ” ë‚ ì§œ ì¸ë±ìŠ¤ ì¶”ì¶œ
        # X_esnì˜ ì „ì²´ ê¸¸ì´ëŠ” len(df) - seq_len
        # esn_val_split_start_idxëŠ” X_esn ê¸°ì¤€ìœ¼ë¡œ split_index
        esn_full_len = len(df) - seq_len
        esn_val_split_start_idx = int(esn_full_len * esn_split_ratio)

        # ESN ì˜ˆì¸¡ê°’ì˜ ë‚ ì§œëŠ” ì‹¤ì œ df ì¸ë±ìŠ¤ì—ì„œ seq_lenì„ ë”í•œ ê°’ì—ì„œ ì‹œì‘
        esn_pred_dates = df.index[seq_len + esn_val_split_start_idx: seq_len + esn_full_len]

        # ESN ì˜ˆì¸¡ê°’ì„ Seriesë¡œ ë³€í™˜
        esn_predicted_series_for_plot = pd.Series(pred_val_esn_close.flatten(), index=esn_pred_dates)
        esn_true_series_for_plot = pd.Series(real_val_esn_close.flatten(), index=esn_pred_dates)

        gru_predicted_recent_plot = gru_predicted_series_for_plot.loc[start_date_plot:].groupby(level=0).mean()
        lstm_predicted_recent_plot = lstm_predicted_series_for_plot.loc[start_date_plot:].groupby(level=0).mean()
        prophet_predicted_recent_plot = prophet_predicted_series.loc[start_date_plot:].groupby(level=0).mean()
        esn_predicted_recent_plot = esn_predicted_series_for_plot.loc[start_date_plot:].groupby(level=0).mean()

        common_dates_plot_all = actual_daily_plot.index.intersection(gru_predicted_recent_plot.index).intersection(
            lstm_predicted_recent_plot.index).intersection(prophet_predicted_recent_plot.index).intersection(
            esn_predicted_recent_plot.index)

        actual_common_plot = actual_daily_plot.loc[common_dates_plot_all]
        gru_predicted_common_plot_for_eval = gru_predicted_recent_plot.loc[common_dates_plot_all]
        lstm_predicted_common_plot_for_eval = lstm_predicted_recent_plot.loc[common_dates_plot_all]
        prophet_predicted_common_plot_for_eval = prophet_predicted_recent_plot.loc[common_dates_plot_all]
        esn_predicted_common_plot_for_eval = esn_predicted_recent_plot.loc[common_dates_plot_all]

        # í‰ê°€ ì§€í‘œ ê³„ì‚° (ìµœê·¼ 100ì¼ ì˜ˆì¸¡)
        gru_mse = mean_squared_error(actual_common_plot, gru_predicted_common_plot_for_eval)
        gru_rmse = np.sqrt(gru_mse)
        gru_mae = mean_absolute_error(actual_common_plot, gru_predicted_common_plot_for_eval)
        gru_r2 = r2_score(actual_common_plot, gru_predicted_common_plot_for_eval)

        lstm_mse = mean_squared_error(actual_common_plot, lstm_predicted_common_plot_for_eval)
        lstm_rmse = np.sqrt(lstm_mse)
        lstm_mae = mean_absolute_error(actual_common_plot, lstm_predicted_common_plot_for_eval)
        lstm_r2 = r2_score(actual_common_plot, lstm_predicted_common_plot_for_eval)

        prophet_mse = mean_squared_error(actual_common_plot, prophet_predicted_common_plot_for_eval)
        prophet_rmse = np.sqrt(prophet_mse)
        prophet_mae = mean_absolute_error(actual_common_plot, prophet_predicted_common_plot_for_eval)
        prophet_r2 = r2_score(actual_common_plot, prophet_predicted_common_plot_for_eval)

        esn_mse = mean_squared_error(actual_common_plot, esn_predicted_common_plot_for_eval)
        esn_rmse = np.sqrt(esn_mse)
        esn_mae = mean_absolute_error(actual_common_plot, esn_predicted_common_plot_for_eval)
        esn_r2 = r2_score(actual_common_plot, esn_predicted_common_plot_for_eval)

        print(f"\n--- ëª¨ë¸ ì˜ˆì¸¡ ì„±ëŠ¥ (ìµœê·¼ 100ì¼) ---")
        print(f"GRU (GA Tuned) - MSE: {gru_mse:.4f}, RMSE: {gru_rmse:.4f}, MAE: {gru_mae:.4f}, R2: {gru_r2:.4f}")
        print(f"LSTM - MSE: {lstm_mse:.4f}, RMSE: {lstm_rmse:.4f}, MAE: {lstm_mae:.4f}, R2: {lstm_r2:.4f}")
        print(
            f"Prophet - MSE: {prophet_mse:.4f}, RMSE: {prophet_rmse:.4f}, MAE: {prophet_mae:.4f}, R2: {prophet_r2:.4f}")
        print(f"ESN - MSE: {esn_mse:.4f}, RMSE: {esn_rmse:.4f}, MAE: {esn_mae:.4f}, R2: {esn_r2:.4f}")

        # ì‹œê°í™” (GRU & LSTM & Prophet & ESN ëª¨ë¸ ë¹„êµ - ìµœê·¼ 100ì¼)
        plt.figure(figsize=(14, 8))
        plt.plot(actual_common_plot.index, actual_common_plot.values, label="ğŸ“ˆ ì‹¤ì œ ì¢…ê°€", color='black',
                 linewidth=2)
        plt.plot(gru_predicted_common_plot_for_eval.index, gru_predicted_common_plot_for_eval.values,
                 label=f"ğŸ§  GRU ì˜ˆì¸¡ (GA Tuned)", color='blue', linestyle='--', linewidth=2)
        plt.plot(lstm_predicted_common_plot_for_eval.index, lstm_predicted_common_plot_for_eval.values,
                 label="ğŸ”® LSTM ì˜ˆì¸¡", color='red', linestyle='--', linewidth=2)
        plt.plot(prophet_predicted_common_plot_for_eval.index, prophet_predicted_common_plot_for_eval.values,
                 label="ğŸ“Š Prophet ì˜ˆì¸¡", color='green', linestyle='--', linewidth=2)
        plt.plot(esn_predicted_common_plot_for_eval.index, esn_predicted_common_plot_for_eval.values,
                 label="ğŸ”„ ESN ì˜ˆì¸¡", color='purple', linestyle='--', linewidth=2)
        plt.title("GOOGL - ìµœê·¼ 100ì¼ ì˜ˆì¸¡ ë¹„êµ: GRU (GA Tuned) vs LSTM vs Prophet vs ESN", fontsize=14)
        plt.xlabel("ë‚ ì§œ")
        plt.ylabel("ê°€ê²© (USD)")
        plt.legend()
        plt.grid(True)
        plt.text(0.01, 0.90, f'GRU (GA) MSE: {gru_mse:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.87, f'GRU (GA) RMSE: {gru_rmse:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.84, f'GRU (GA) MAE: {gru_mae:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.81, f'GRU (GA) R2: {gru_r2:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.76, f'LSTM MSE: {lstm_mse:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.73, f'LSTM RMSE: {lstm_rmse:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.70, f'LSTM MAE: {lstm_mae:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.67, f'LSTM R2: {lstm_r2:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.62, f'Prophet MSE: {prophet_mse:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.59, f'Prophet RMSE: {prophet_rmse:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.56, f'Prophet MAE: {prophet_mae:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.53, f'Prophet R2: {prophet_r2:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.48, f'ESN MSE: {esn_mse:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.45, f'ESN RMSE: {esn_rmse:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.42, f'ESN MAE: {esn_mae:.4f}', transform=plt.gca().transAxes)
        plt.text(0.01, 0.39, f'ESN R2: {esn_r2:.4f}', transform=plt.gca().transAxes)
        plt.tight_layout()
        plt.show()

        fig, ax = plt.subplots(figsize=(9, 3))
        ax.axis('off')

        col_labels = ["MSE", "RMSE", "MAE", "RÂ²"]
        row_labels = ["GRU (GA)", "LSTM", "Prophet", "ESN"]
        cell_text = [
            [gru_mse, gru_rmse, gru_mae, gru_r2],
            [lstm_mse, lstm_rmse, lstm_mae, lstm_r2],
            [prophet_mse, prophet_rmse, prophet_mae, prophet_r2],
            [esn_mse, esn_rmse, esn_mae, esn_r2],
        ]

        table = ax.table(cellText=cell_text,
                         rowLabels=row_labels,
                         colLabels=col_labels,
                         cellLoc='center',
                         loc='center')

        table.scale(1.2, 1.8)
        table.auto_set_font_size(False)
        table.set_fontsize(11)
        table.auto_set_column_width(col=list(range(len(col_labels))))

        plt.title("ìµœê·¼ 100ì¼ ì˜ˆì¸¡ ì„±ëŠ¥ ë¹„êµ", fontsize=13, weight='bold', pad=12)
        plt.tight_layout()
        plt.show()

        # ì˜ˆì¸¡ ì˜¤ì°¨ ê³„ì‚° (ìµœê·¼ 100ì¼ ê¸°ì¤€, ì´ë¯¸ êµì°¨ëœ ë‚ ì§œ ê¸°ì¤€)
        if not actual_common_plot.empty:
            gru_errors = np.abs(actual_common_plot.values - gru_predicted_common_plot_for_eval.values)
            lstm_errors = np.abs(actual_common_plot.values - lstm_predicted_common_plot_for_eval.values)
            prophet_errors = np.abs(actual_common_plot.values - prophet_predicted_common_plot_for_eval.values)
            esn_errors = np.abs(actual_common_plot.values - esn_predicted_common_plot_for_eval.values)

            # GRU vs LSTM
            t_stat_gru_lstm, p_value_gru_lstm = ttest_rel(gru_errors, lstm_errors)
            print(f"\nğŸ“Š í†µê³„ ê²€ì • ê²°ê³¼ (GRU vs LSTM ì˜ˆì¸¡ ì˜¤ì°¨):")
            print(f"t-statistic: {t_stat_gru_lstm:.4f}")
            print(f"p-value: {p_value_gru_lstm:.4f}")
            if p_value_gru_lstm < 0.05:
                print("âœ… ê·€ë¬´ê°€ì„¤ ê¸°ê°: GRUì™€ LSTM ê°„ ì˜ˆì¸¡ ì„±ëŠ¥ ì°¨ì´ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•©ë‹ˆë‹¤.")
            else:
                print("âš ï¸ ê·€ë¬´ê°€ì„¤ ì±„íƒ: GRUì™€ LSTM ê°„ ì˜ˆì¸¡ ì„±ëŠ¥ ì°¨ì´ëŠ” ìœ ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            # GRU vs Prophet
            t_stat_gru_prophet, p_value_gru_prophet = ttest_rel(gru_errors, prophet_errors)
            print(f"\nğŸ“Š í†µê³„ ê²€ì • ê²°ê³¼ (GRU vs Prophet ì˜ˆì¸¡ ì˜¤ì°¨):")
            print(f"t-statistic: {t_stat_gru_prophet:.4f}")
            print(f"p-value: {p_value_gru_prophet:.4f}")
            if p_value_gru_prophet < 0.05:
                print("âœ… ê·€ë¬´ê°€ì„¤ ê¸°ê°: GRUì™€ Prophet ê°„ ì˜ˆì¸¡ ì„±ëŠ¥ ì°¨ì´ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•©ë‹ˆë‹¤.")
            else:
                print("âš ï¸ ê·€ë¬´ê°€ì„¤ ì±„íƒ: GRUì™€ Prophet ê°„ ì˜ˆì¸¡ ì„±ëŠ¥ ì°¨ì´ëŠ” ìœ ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            # GRU vs ESN
            t_stat_gru_esn, p_value_gru_esn = ttest_rel(gru_errors, esn_errors)
            print(f"\nğŸ“Š í†µê³„ ê²€ì • ê²°ê³¼ (GRU vs ESN ì˜ˆì¸¡ ì˜¤ì°¨):")
            print(f"t-statistic: {t_stat_gru_esn:.4f}")
            print(f"p-value: {p_value_gru_esn:.4f}")
            if p_value_gru_esn < 0.05:
                print("âœ… ê·€ë¬´ê°€ì„¤ ê¸°ê°: GRUì™€ ESN ê°„ ì˜ˆì¸¡ ì„±ëŠ¥ ì°¨ì´ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•©ë‹ˆë‹¤.")
            else:
                print("âš ï¸ ê·€ë¬´ê°€ì„¤ ì±„íƒ: GRUì™€ ESN ê°„ ì˜ˆì¸¡ ì„±ëŠ¥ ì°¨ì´ëŠ” ìœ ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            # LSTM vs Prophet
            t_stat_lstm_prophet, p_value_lstm_prophet = ttest_rel(lstm_errors, prophet_errors)
            print(f"\nğŸ“Š í†µê³„ ê²€ì • ê²°ê³¼ (LSTM vs Prophet ì˜ˆì¸¡ ì˜¤ì°¨):")
            print(f"t-statistic: {t_stat_lstm_prophet:.4f}")
            print(f"p-value: {p_value_lstm_prophet:.4f}")
            if p_value_lstm_prophet < 0.05:
                print("âœ… ê·€ë¬´ê°€ì„¤ ê¸°ê°: LSTMê³¼ Prophet ê°„ ì˜ˆì¸¡ ì„±ëŠ¥ ì°¨ì´ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•©ë‹ˆë‹¤.")
            else:
                print("âš ï¸ ê·€ë¬´ê°€ì„¤ ì±„íƒ: LSTMê³¼ Prophet ê°„ ì˜ˆì¸¡ ì„±ëŠ¥ ì°¨ì´ëŠ” ìœ ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            # LSTM vs ESN
            t_stat_lstm_esn, p_value_lstm_esn = ttest_rel(lstm_errors, esn_errors)
            print(f"\nğŸ“Š í†µê³„ ê²€ì • ê²°ê³¼ (LSTM vs ESN ì˜ˆì¸¡ ì˜¤ì°¨):")
            print(f"t-statistic: {t_stat_lstm_esn:.4f}")
            print(f"p-value: {p_value_lstm_esn:.4f}")
            if p_value_lstm_esn < 0.05:
                print("âœ… ê·€ë¬´ê°€ì„¤ ê¸°ê°: LSTMê³¼ ESN ê°„ ì˜ˆì¸¡ ì„±ëŠ¥ ì°¨ì´ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•©ë‹ˆë‹¤.")
            else:
                print("âš ï¸ ê·€ë¬´ê°€ì„¤ ì±„íƒ: LSTMê³¼ ESN ê°„ ì˜ˆì¸¡ ì„±ëŠ¥ ì°¨ì´ëŠ” ìœ ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            # Prophet vs ESN
            t_stat_prophet_esn, p_value_prophet_esn = ttest_rel(prophet_errors, esn_errors)
            print(f"\nğŸ“Š í†µê³„ ê²€ì • ê²°ê³¼ (Prophet vs ESN ì˜ˆì¸¡ ì˜¤ì°¨):")
            print(f"t-statistic: {t_stat_prophet_esn:.4f}")
            print(f"p-value: {p_value_prophet_esn:.4f}")
            if p_value_prophet_esn < 0.05:
                print("âœ… ê·€ë¬´ê°€ì„¤ ê¸°ê°: Prophetê³¼ ESN ê°„ ì˜ˆì¸¡ ì„±ëŠ¥ ì°¨ì´ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•©ë‹ˆë‹¤.")
            else:
                print("âš ï¸ ê·€ë¬´ê°€ì„¤ ì±„íƒ: Prophetê³¼ ESN ê°„ ì˜ˆì¸¡ ì„±ëŠ¥ ì°¨ì´ëŠ” ìœ ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            print("ê²½ê³ : ì˜ˆì¸¡ ì˜¤ì°¨ í†µê³„ ê²€ì •ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

        # 10. ì „ì²´ ì˜ˆì¸¡ ì‹œê°í™” (GRU & LSTM & Prophet & ESN ëª¨ë¸ ë¹„êµ)
        gru_pred_full_all_data = gru_model_final.predict(X)
        gru_predicted_full_inv = close_scaler.inverse_transform(gru_pred_full_all_data)[:, -1]

        lstm_pred_full_all_data = lstm_model_final.predict(X)
        lstm_predicted_full_inv = close_scaler.inverse_transform(lstm_pred_full_all_data)[:, -1]

        actual_full_inv = close_scaler.inverse_transform(y)[:, -1]

        dates_full_plot = df.index[seq_len: seq_len + len(X)]

        prophet_predicted_full_plot = prophet_predicted_series.loc[dates_full_plot].values

        # ESN ì „ì²´ ì˜ˆì¸¡ (X_esnì„ ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡)
        # ESNì€ ë‹¨ì¼ ìŠ¤í… ì˜ˆì¸¡ì´ë¯€ë¡œ, ë§ˆì§€ë§‰ 'y_esn'ì„ ì „ì²´ ì˜ˆì¸¡ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        # run_esn í•¨ìˆ˜ì—ì„œ ì‹¤ì œ 'X_esn_val'ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ë°˜í™˜í•˜ë¯€ë¡œ,
        # ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ESN ì˜ˆì¸¡ì„ ìœ„í•´ì„œëŠ” `run_esn` ë‚´ë¶€ì—ì„œ `esn.predict(X_esn)` (ì „ì²´ X_esn)ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ `pred_val_esn_close` (ê²€ì¦ì…‹ ì˜ˆì¸¡ê°’)ì„ ì „ì²´ ì˜ˆì¸¡ì˜ ì¼ë¶€ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
        # í•˜ì§€ë§Œ, ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ í•˜ë ¤ë©´ ESN ëª¨ë¸ì„ ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ë‹¤ì‹œ í•™ìŠµì‹œí‚¤ê³  ì˜ˆì¸¡í•´ì•¼ í•©ë‹ˆë‹¤.
        # ê¸°ì¡´ `run_esn` í•¨ìˆ˜ëŠ” í›ˆë ¨/ê²€ì¦ ë¶„í• ì„ í•˜ê¸° ë•Œë¬¸ì—, ì „ì²´ ì˜ˆì¸¡ì„ ìœ„í•´ì„œëŠ” ESN ëª¨ë¸ì„ ë‹¤ì‹œ ë§Œë“¤ê³  `esn.fit(X_esn, y_esn)` í›„ `esn.predict(X_esn)`ì„ í•´ì•¼ í•©ë‹ˆë‹¤.
        # í¸ì˜ìƒ, ì—¬ê¸°ì„œëŠ” `run_esn`ì—ì„œ ë‚˜ì˜¨ `pred_val_esn_close`ì™€ `esn_true_series_for_plot`ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        # ì¦‰, ì „ì²´ ê¸°ê°„ì´ ì•„ë‹Œ, ESNì˜ ê²€ì¦ì…‹ ê¸°ê°„ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ë§Œ ì‹œê°í™”ë©ë‹ˆë‹¤.

        # ì „ì²´ ê¸°ê°„ì— ëŒ€í•œ ESN ì˜ˆì¸¡ì„ ì–»ê¸° ìœ„í•œ ì¶”ê°€ ì½”ë“œ (ì˜µì…˜)
        # ESN ëª¨ë¸ì„ ì „ì²´ ë°ì´í„°ì— ë‹¤ì‹œ í•™ìŠµ (ì „ì²´ ê¸°ê°„ ì˜ˆì¸¡ì„ ìœ„í•¨)
        print("\n--- ESN ìµœì¢… ëª¨ë¸ (ì „ì²´ ë°ì´í„°) í•™ìŠµ ì‹œì‘ ---")
        # X_esn_full_data_rawëŠ” ëª¨ë“  íŠ¹ì„± (scaled_full)ì„ ì‚¬ìš©
        X_esn_full_data_raw_for_input, _ = create_ESN_sequences(scaled_full, seq_len)
        X_esn_full_data = X_esn_full_data_raw_for_input.reshape(
            X_esn_full_data_raw_for_input.shape[0], seq_len * scaled_full.shape[1]
        )

        # y_esn_full_data_rawëŠ” ì¢…ê°€ (scaled_close)ë§Œ ì‚¬ìš©
        _, y_esn_full_data_raw_for_target = create_ESN_sequences(scaled_close, seq_len)
        # y_esn_full_dataëŠ” 1ì°¨ì›ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
        y_esn_full_data = y_esn_full_data_raw_for_target.flatten()  # (num_sequences,)

        esn_full_model = ESN(
            n_inputs=X_esn_full_data.shape[1],
            n_outputs=1,  # ì¢…ê°€ 1ê°œ ì˜ˆì¸¡
            n_reservoir=200,
            spectral_radius=0.95,
            sparsity=0.2,
            noise=0.001,
            random_state=42
        )
        esn_full_model.fit(X_esn_full_data, y_esn_full_data)
        esn_predicted_full_scaled = esn_full_model.predict(X_esn_full_data)
        esn_predicted_full_scaled = np.clip(esn_predicted_full_scaled, 0, 1)
        esn_predicted_full_inv = close_scaler.inverse_transform(esn_predicted_full_scaled.reshape(-1, 1)).flatten()

        # ESN ì „ì²´ ì˜ˆì¸¡ì˜ ë‚ ì§œ ì¸ë±ìŠ¤
        esn_dates_full_plot = df.index[seq_len: seq_len + len(esn_predicted_full_inv)]

        plt.figure(figsize=(14, 6))
        plt.plot(dates_full_plot, actual_full_inv, label="ğŸ“ˆ ì‹¤ì œ ì¢…ê°€", color='black')
        plt.plot(dates_full_plot, gru_predicted_full_inv, label=f"ğŸ§  GRU ì˜ˆì¸¡ (GA Tuned)", color='blue',
                 linestyle='--')
        plt.plot(dates_full_plot, lstm_predicted_full_inv, label="ğŸ”® LSTM ì˜ˆì¸¡", color='red', linestyle='--')
        plt.plot(dates_full_plot, prophet_predicted_full_plot, label="ğŸ“Š Prophet ì˜ˆì¸¡", color='green', linestyle='--')
        plt.plot(esn_dates_full_plot, esn_predicted_full_inv, label="ğŸ”„ ESN ì˜ˆì¸¡", color='purple', linestyle='--')
        plt.title("GOOGL - ì „ì²´ ê¸°ê°„ ì˜ˆì¸¡ ë¹„êµ (~3000ì¼): GRU / LSTM / Prophet / ESN")
        plt.xlabel("ë‚ ì§œ")
        plt.ylabel("ê°€ê²© (USD)")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()

        # 11. GC/DC ì‹œì  ì‹œê°í™”
        plt.figure(figsize=(14, 6))
        plt.plot(df.index, df['Close'], label="Close", color='black')
        plt.scatter(df.index[df['GC'] == 1], df['Close'][df['GC'] == 1], marker='^', color='green',
                    label="Golden Cross")
        plt.scatter(df.index[df['DC'] == -1], df['Close'][df['DC'] == -1], marker='v', color='red', label="Dead Cross")
        plt.title("GOOGL - Golden/Dead Cross Points")
        plt.xlabel("ë‚ ì§œ");
        plt.ylabel("ê°€ê²©")
        plt.legend();
        plt.grid(True);
        plt.tight_layout()
        plt.show()

        # 12. GC/DC Signal ì‹œê°í™”
        plt.figure(figsize=(14, 4))
        plt.plot(df.index, df['GC/DC Signal'], color='purple')
        plt.title("GC/DC Signal Time Series (1 = GC, -1 = DC)")
        plt.xlabel("ë‚ ì§œ");
        plt.ylabel("ì‹ í˜¸")
        plt.yticks([-1, 0, 1], ['Dead Cross', 'None', 'Golden Cross'])
        plt.grid(True);
        plt.tight_layout()
        plt.show()

        # 13. ì´ë™í‰ê· ì„  ì‹œê°í™”
        plt.figure(figsize=(14, 6))
        plt.plot(df.index, df['Close'], label='Close', color='black')
        plt.plot(df.index, df['MA7'], label='MA7', color='blue', linestyle='--')
        plt.plot(df.index, df['MA14'], label='MA14', color='orange', linestyle='--')
        plt.plot(df.index, df['MA50'], label='MA50', color='green', linestyle='--')
        plt.title("GOOGL - ì´ë™í‰ê· ì„ ê³¼ ê°€ê²© ì¶”ì´")
        plt.xlabel("ë‚ ì§œ");
        plt.ylabel("ê°€ê²©")
        plt.legend();
        plt.grid(True);
        plt.tight_layout()
        plt.show()


        # --- MDD, Sharpe Ratio ê³„ì‚° í•¨ìˆ˜ë“¤ (ESN ë…ë¦½ì ) ---
        def calculate_mdd(equity_curve):
            if equity_curve.empty or len(equity_curve) < 2:
                return 0.0
            peak = equity_curve.cummax()
            drawdown = (equity_curve - peak) / peak
            return drawdown.min() * -1


        def calculate_sharpe_ratio(returns_series, risk_free_rate=0.02 / 252):
            if returns_series.empty or returns_series.std() == 0:
                return 0.0
            daily_returns = returns_series.dropna()
            if daily_returns.std() == 0:
                return 0.0
            excess_returns = daily_returns - risk_free_rate
            return excess_returns.mean() / daily_returns.std() * np.sqrt(252)


        # 14. GC/DC ì „ëµ ìˆ˜ìµë¥  ë¶„ì„ ë° ì„±ëŠ¥ì§€í‘œ í‰ê°€ (ì›ë³¸ GC/DC)
        df_signals = df[df['GC/DC Signal'] != 0].copy()

        strategy_daily_returns_original_gc_dc = pd.Series(0.0, index=df.index)
        position = 0

        for i in range(1, len(df)):
            date = df.index[i]
            prev_date = df.index[i - 1]

            current_close_price = df['Close'].iloc[i]
            prev_close_price = df['Close'].iloc[i - 1]

            gc_signal = df['GC'].iloc[i]
            dc_signal = df['DC'].iloc[i]

            if position == 1:
                strategy_daily_returns_original_gc_dc.loc[date] = (
                                                                          current_close_price - prev_close_price) / prev_close_price
            else:
                strategy_daily_returns_original_gc_dc.loc[date] = 0.0

            if gc_signal == 1 and position == 0:
                position = 1
            elif dc_signal == -1 and position == 1:
                position = 0

        cumulative_return_original_gc_dc = (1 + strategy_daily_returns_original_gc_dc).cumprod()
        if cumulative_return_original_gc_dc.empty:
            cumulative_return_original_gc_dc = pd.Series([1.0], index=[df.index[0]])

        sharpe_original_gc_dc = calculate_sharpe_ratio(strategy_daily_returns_original_gc_dc)
        mdd_original_gc_dc = calculate_mdd(cumulative_return_original_gc_dc)

        print(f"\n GC/DC ì „ëµ í‰ê°€ (MA7/MA50):")
        print(f"  ëˆ„ì  ìˆ˜ìµë¥ : {cumulative_return_original_gc_dc.iloc[-1] * 100:.2f}%")
        print(f"  ìƒ¤í”„ì§€ìˆ˜ (ì—°ìœ¨í™”): {sharpe_original_gc_dc:.4f}")
        print(f"  ìµœëŒ€ ë‚™í­ (MDD): {mdd_original_gc_dc * 100:.2f}%")

        # --- Buy and Hold ì „ëµ í‰ê°€ ---
        buy_and_hold_daily_returns = df['Close'].pct_change().dropna()
        buy_and_hold_cum_return = (1 + buy_and_hold_daily_returns).cumprod()
        if buy_and_hold_cum_return.empty:
            buy_and_hold_cum_return = pd.Series([1.0], index=[df.index[0]])

        buy_and_hold_sharpe = calculate_sharpe_ratio(buy_and_hold_daily_returns)
        buy_and_hold_mdd = calculate_mdd(buy_and_hold_cum_return)

        print(f"\n Buy and Hold ì „ëµ í‰ê°€:")
        print(f"  ëˆ„ì  ìˆ˜ìµë¥ : {buy_and_hold_cum_return.iloc[-1] * 100:.2f}%")
        print(f"  ìƒ¤í”„ì§€ìˆ˜ (ì—°ìœ¨í™”): {buy_and_hold_sharpe:.4f}")
        print(f"  ìµœëŒ€ ë‚™í­ (MDD): {buy_and_hold_mdd * 100:.2f}%")

        # --- ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ ê·¸ë˜í”„ (ì›ë³¸ GC/DC vs Buy & Hold) ---
        plt.figure(figsize=(14, 6))
        plt.plot(cumulative_return_original_gc_dc.index, cumulative_return_original_gc_dc.values,
                 label="GC/DC ì „ëµ ëˆ„ì  ìˆ˜ìµë¥ ", color='green')
        plt.plot(buy_and_hold_cum_return.index, buy_and_hold_cum_return.values, label="ë§¤ìˆ˜ í›„ ë³´ìœ  ì „ëµ ëˆ„ì  ìˆ˜ìµë¥ ",
                 color='blue', linestyle='--')
        plt.title("ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ (GC/DC vs ë§¤ìˆ˜ í›„ ë³´ìœ )", fontsize=14)
        plt.xlabel("ë‚ ì§œ")
        plt.ylabel("ëˆ„ì  ìˆ˜ìµë¥  (ë°°ìœ¨)")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()

        # --- ìµœê·¼ 100ì¼ ì˜ˆì¸¡ ì •í™•ë„ ë¹„êµ (êµ¬ê°„ë³„ MSE ì¶”ì¶œ) ---
        if gru_predicted_common_tss.size > 0 and lstm_predicted_common_tss.size > 0:
            min_len_tss = min(len(actual_common_gru_tss), len(gru_predicted_common_tss), len(lstm_predicted_common_tss))

            chunk_size = min_len_tss // 5
            gru_mse_arr, lstm_mse_arr = [], []

            for i in range(5):
                start = i * chunk_size
                end = (i + 1) * chunk_size if (i + 1) * chunk_size <= min_len_tss else min_len_tss

                if start < end:
                    mse_gru = mean_squared_error(actual_common_gru_tss[start:end, 0],
                                                 gru_predicted_common_tss[start:end, 0])
                    mse_lstm = mean_squared_error(actual_common_lstm_tss[start:end, 0],
                                                  lstm_predicted_common_tss[start:end, 0])
                    gru_mse_arr.append(mse_gru)
                    lstm_mse_arr.append(mse_lstm)

            if gru_mse_arr and lstm_mse_arr:
                gru_mse_arr = np.array(gru_mse_arr)
                lstm_mse_arr = np.array(lstm_mse_arr)

                t_stat_mse, p_value_mse = stats.ttest_ind(gru_mse_arr, lstm_mse_arr)
                print(f"\nğŸ“Š t-ê²€ì • í†µê³„ëŸ‰ (MSE êµ¬ê°„ - TSS ê²°ê³¼): {t_stat_mse:.4f}, p-value: {p_value_mse:.5f}")
                if p_value_mse < 0.05:
                    print("âœ… ëŒ€ë¦½ê°€ì„¤ ì±„íƒ: GRUì™€ LSTM ê°„ MSE ì„±ëŠ¥ ì°¨ì´ê°€ ìœ ì˜ë¯¸í•¨.")
                else:
                    print("âœ… ê·€ë¬´ê°€ì„¤ ì±„íƒ: GRUì™€ LSTM ê°„ MSE ì„±ëŠ¥ ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ.")
            else:
                print("ê²½ê³ : MSE êµ¬ê°„ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (TSS ê²°ê³¼).")
        else:
            print("ê²½ê³ : MSE êµ¬ê°„ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (TSS ê²°ê³¼).")

        # ìµœê·¼ êµ¬ê°„ í‰ê°€ (Prophet í¬í•¨)
        if 'Date' not in df.columns:
            df = df.reset_index()
        df["Date"] = pd.to_datetime(df["Date"])
        df_eval = df.copy()
        df.set_index("Date", inplace=True)

        pred_results = {
            "GRU": gru_predicted_series_for_plot,
            "LSTM": lstm_predicted_series_for_plot,
            "Prophet": prophet_predicted_series,
            "ESN": esn_predicted_series_for_plot  # ESN ì¶”ê°€
        }

        eval_periods = {
            "1Y": pd.DateOffset(years=1),
            "6M": pd.DateOffset(months=6),
            "3M": pd.DateOffset(months=3),
            "1M": pd.DateOffset(months=1)
        }


        def compute_return_and_mdd(series: pd.Series) -> tuple:
            if series.empty or len(series) < 2:
                return 0.0, 0.0
            if series.iloc[0] == 0:
                return 0.0, 0.0
            cum_return = series / series.iloc[0]
            mdd = (cum_return / cum_return.cummax() - 1).min()
            total_return = cum_return.iloc[-1] - 1
            return total_return, mdd


        eval_results = []
        for label, offset in eval_periods.items():
            start_date_eval = df_eval["Date"].max() - offset
            test_dates_in_period = df.index[df.index >= start_date_eval]

            for model_name, pred_series in pred_results.items():
                pred_filtered = pred_series.reindex(test_dates_in_period).dropna()
                actual_filtered = df["Close"].reindex(pred_filtered.index).dropna()
                common_idx = actual_filtered.index.intersection(pred_filtered.index)
                actual_vals = actual_filtered.loc[common_idx]
                pred_vals = pred_filtered.loc[common_idx]

                if len(common_idx) < 2 or actual_vals.empty or pred_vals.empty:
                    print(f"ê²½ê³ : {label} ê¸°ê°„, {model_name} ëª¨ë¸ì— ëŒ€í•œ í‰ê°€ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                    continue

                mse = mean_squared_error(actual_vals, pred_vals)
                rmse = np.sqrt(mse)
                mae = mean_absolute_error(actual_vals, pred_vals)
                r2 = r2_score(actual_vals, pred_vals)
                ret, mdd = compute_return_and_mdd(pred_vals)

                eval_results.append({
                    "Period": label,
                    "Model": model_name,
                    "MSE": mse,
                    "RMSE": rmse,
                    "MAE": mae,
                    "R2": r2,
                    "Return": ret,
                    "MDD": mdd
                })

if eval_results:
    eval_df = pd.DataFrame(eval_results)
    import seaborn as sns

    sns.set(style="whitegrid")
    # í•œê¸€ í°íŠ¸ ì„¤ì • (Windows ê¸°ì¤€)
    if platform.system() == 'Windows':
        plt.rcParams['font.family'] = 'Malgun Gothic'
    metrics = ["R2", "Return", "MDD"]
    for metric in metrics:
        if not eval_df.empty:
            plt.figure(figsize=(10, 5))
            sns.barplot(data=eval_df, x="Period", y=metric, hue="Model")
            plt.title(f"{metric} (ê¸°ê°„ ë° ëª¨ë¸ë³„)", fontsize=14)
            plt.ylabel(metric)
            plt.xlabel("í‰ê°€ ê¸°ê°„")
            plt.legend(title="ëª¨ë¸")
            plt.tight_layout()
            plt.show()
        else:
            print(f"ê²½ê³ : {metric} ì‹œê°í™”ë¥¼ ìœ„í•œ í‰ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    print("ê²½ê³ : ëª¨ë“  í‰ê°€ ê¸°ê°„ ë° ëª¨ë¸ì— ëŒ€í•œ ê²°ê³¼ê°€ ë¶€ì¡±í•˜ì—¬ ì„±ëŠ¥ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
